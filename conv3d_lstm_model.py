# -*- coding: utf-8 -*-
"""conv3d_lstm_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YzD0hnb6cNzZHC_wwmNrPmYjimLCywd0
"""

from google.colab import drive

import numpy as np
import os
import imutils
import dlib
import cv2

import imageio
from imutils import face_utils


import time
import os

# Google Colab
#drive.mount('/content/gdrive')
#os.environ
#os.environ['KAGGLE_CONFIG_DIR']='/content/gdrive/My Drive/datasets'
# %cd /content/gdrive/My Drive/datasets/miraclvc1

people = ['F01','F02','F04','F05','F06','F07','F08','F09','F10','F11','M01','M02','M04','M07','M08']
folder_enum = ['01','02','03','04','05','06','07','08', '09', '10']
instances = ['01','02','03','04','05','06','07','08', '09', '10']
data_types = ['words']
words = ['Begin', 'Choose', 'Connection', 'Navigation', 'Next', 'Previous', 'Start', 'Stop', 'Hello', 'Web']

import pickle

from keras.utils import np_utils, generic_utils

with open('pickle_train_test/X_train.pkl', 'rb') as f:
   X_train = pickle.load(f)

with open('pickle_train_test/y_train.pkl', 'rb') as f:
   y_train = pickle.load(f)

with open('pickle_train_test/X_test.pkl', 'rb') as f:
   X_test = pickle.load(f)

with open('pickle_train_test/y_test.pkl', 'rb') as f:
   y_test = pickle.load(f)

with open('pickle_train_test/X_val.pkl', 'rb') as f:
   X_val = pickle.load(f)

with open('pickle_train_test/y_val.pkl', 'rb') as f:
   y_val = pickle.load(f)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)
print(X_val.shape)
print(y_val.shape)

"""Model Building"""

from tensorflow.keras.layers import Conv3D, MaxPooling3D
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Activation, ZeroPadding3D, TimeDistributed, LSTM, GRU, Reshape
from tensorflow.keras.utils import plot_model
from tensorflow.keras.layers import BatchNormalization
import matplotlib.pyplot as plt

from tensorflow import keras

#CNN + LSTM

model = Sequential()

# 1st layer group
model.add(Conv3D(32, (3, 3, 3), strides = 1, input_shape=(22, 100, 100, 1), activation='relu', padding='valid'))
model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))

model.add(Conv3D(64, (3, 3, 3), activation='relu', strides=1))
model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))

model.add(Conv3D(128, (3, 3, 3), activation='relu', strides=1))
model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=2))
#(None, 1, 10, 10, 128)
# shape = model.get_output_shape_at(0)
#model.add(Reshape((shape[-1],shape[1]*shape[2]*shape[3])))

model.add(Reshape((128, 1*10*10)))

# LSTMS - Recurrent Network Layer
model.add(LSTM(32, return_sequences=True))
model.add(Dropout(.5))

model.add((Flatten()))

# # FC layers group
model.add(Dense(2048, activation='relu'))
model.add(Dropout(.5))
model.add(Dense(1024, activation='relu'))
model.add(Dropout(.5))

model.add(Dense(10, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.summary()

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor="val_loss", patience=4)

t1 = time.time()
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=45)
t2 = time.time()
print()
print(f"Training time : {t2 - t1} secs.")

"""Training and validation accuracy"""

# Plot training & validation accuracy values
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.xlim(1, 40)
# plt.ylim(0, 3)
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

ypred = model.predict(X_test)

ypred[0]

predicted_words = [words[i] for i in np.argmax(ypred, axis=1)]
actual_words = [words[i] for i in np.argmax(y_test, axis=1)]

correct = 0
for p, a in zip(predicted_words, actual_words):
    if p == a:
        correct += 1
#     print(f"Predicted : {p} \t Actual : {a}")

accuracy = correct/len(actual_words)
print(f"Accuracy = {accuracy} on completely unseen data")

model.evaluate(X_test, y_test)

model.metrics_names

my_data = X_test[0]
my_data.shape

# my_data

X_train[0].shape

my_data = my_data.reshape(1,22,100,100,1)

ans = model.predict(my_data)
np.argmax(ans,)

y_test[0]

# Commented out IPython magic to ensure Python compatibility.
#Model Saving
# %pwd

# model.save_weights('saved_model/')

model.save('complete_saved_model_45e')